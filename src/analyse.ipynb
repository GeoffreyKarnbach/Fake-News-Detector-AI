{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit"
  },
  "interpreter": {
   "hash": "38740d3277777e2cd7c6c2cc9d8addf5118fdf3f82b1b39231fd12aeac8aee8b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Imports of pandas, seaborn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from itertools import islice\n",
    "import nltk\n",
    "from nameparser.parser import HumanName\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(10,8)})\n",
    "sns.set_palette(\"hls\")"
   ]
  },
  {
   "source": [
    "Download necessary ressources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "source": [
    "Read train dataset from csv file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/kaggle/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "Statistical analysis about length of every \"text\" in dataset - For loop + Sorting by longest articles\n",
    "\n",
    "Generate graph of average length of articles in 100 of characters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"text_length\"] = df[\"text\"].apply(lambda x: math.ceil( len(str(x)) / 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=df[\"text_length\"])\n",
    "ax.locator_params(axis='x', nbins=20)\n",
    "ax.set(xlabel = 'Length of article(in 500s steps)', ylabel='Number of articles', title='Distribution of (all) article length')"
   ]
  },
  {
   "source": [
    "Statistical analysis about length of every fake news (label = 1) in dataset - For loop + Sorting by longest articles\n",
    "\n",
    "Generate graph of average length of articles in 100 of characters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=df.loc[df[\"label\"] == 1][\"text_length\"])\n",
    "ax.locator_params(axis='x', nbins=20)\n",
    "ax.set(xlabel = 'Length of article(in 500s steps)', ylabel='Number of articles', title='Distribution of (fake-news) article length')"
   ]
  },
  {
   "source": [
    "Statistical analysis about length of every non fake news (label = 0) in dataset - For loop + Sorting by longest articles\n",
    "\n",
    "Generate graph of average length of articles in 100 of characters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "ax = sns.countplot(x=df.loc[df[\"label\"] == 0][\"text_length\"])\n",
    "ax.locator_params(axis='x', nbins=20)\n",
    "ax.set(xlabel = 'Length of article(in 500s steps)', ylabel='Number of articles', title='Distribution (non-fake-news) of article length')"
   ]
  },
  {
   "source": [
    "Check amount of names and save result to CSV file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def get_human_names(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    pos = nltk.pos_tag(tokens)\n",
    "    sentt = nltk.ne_chunk(pos, binary = False)\n",
    "    person_list = []\n",
    "    person = []\n",
    "    name = \"\"\n",
    "    for subtree in sentt.subtrees(filter=lambda t: t.label() == 'PERSON'):\n",
    "        for leaf in subtree.leaves():\n",
    "            person.append(leaf[0])\n",
    "        if len(person) > 1: #avoid grabbing lone surnames\n",
    "            for part in person:\n",
    "                name += part + ' '\n",
    "            if name[:-1] not in person_list:\n",
    "                person_list.append(name[:-1])\n",
    "            name = ''\n",
    "        person = []\n",
    "\n",
    "    return len(person_list)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df[\"nb_names\"] = df[\"text\"].progress_apply(lambda x: get_human_names(str(x)))\n",
    "\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "source": [
    "Generate graph for fake news."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_wrangled = pd.read_csv(\"../data/transformed/wrangled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "ax = sns.countplot(x=df_wrangled.loc[df_wrangled[\"label\"] == 1][\"nb_names\"])\n",
    "ax.locator_params(axis='x', nbins=20)\n",
    "ax.set(xlabel = 'Number of names in article', ylabel='Number of articles', title='Distribution of article name usage in fake news')"
   ]
  },
  {
   "source": [
    "Generate graph for non fake news."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "ax = sns.countplot(x=df_wrangled.loc[df_wrangled[\"label\"] == 0][\"nb_names\"])\n",
    "ax.locator_params(axis='x', nbins=20)\n",
    "ax.set(xlabel = 'Number of names in article', ylabel='Number of articles', title='Distribution of article name usage in non-fake news')"
   ]
  },
  {
   "source": [
    "Amount of exclamation marks in fake/ non fake news"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_exclamation_counter = 0\n",
    "non_fake_exclamation_counter = 0\n",
    "\n",
    "for index, row in df.loc[df['text'].str.contains(r'!') == True].iterrows():\n",
    "    if row[\"label\"] == 0:\n",
    "        non_fake_exclamation_counter+=1\n",
    "    else:\n",
    "        fake_exclamation_counter+=1\n",
    "\n",
    "print(f\"Fake exclamation counter : {fake_exclamation_counter}\")\n",
    "print(f\"Non Fake exclamation counter : {non_fake_exclamation_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"exclamation\"] = df[\"text\"].apply(lambda x: x.count(r'!'))"
   ]
  },
  {
   "source": [
    "Check word length in articles"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longer_than_(texte, nb):\n",
    "    counter = 0\n",
    "    for loop in str(texte).split(\" \"):\n",
    "        if len(loop)==nb:\n",
    "            counter+=1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_length = {}\n",
    "for number in range(1,20):\n",
    "    word_length[number]=sum(df[\"text\"].apply(lambda x: longer_than_(x, number)))\n",
    "\n",
    "print(word_length)\n",
    "\n",
    "my_df = pd.DataFrame(word_length.items())\n",
    "ax = sns.barplot(x=0, y=1, data=my_df)\n",
    "ax.set(xlabel = 'Number of letters', ylabel='Number of words in ', title='Amount of words with nb letters')"
   ]
  },
  {
   "source": [
    "Specific for fake news"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_length = {}\n",
    "for number in range(1,20):\n",
    "    word_length[number]=sum(df[\"text\"].loc[df[\"label\"] == 1].apply(lambda x: longer_than_(x, number)))\n",
    "\n",
    "print(word_length)\n",
    "\n",
    "my_df = pd.DataFrame(word_length.items())\n",
    "ax = sns.barplot(x=0, y=1, data=my_df)\n",
    "ax.set(xlabel = 'Number of letters', ylabel='Number of words in ', title='Amount of words with nb letters for fake news')"
   ]
  },
  {
   "source": [
    "Specific for non fake news"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_length = {}\n",
    "for number in range(1,20):\n",
    "    word_length[number]=sum(df[\"text\"].loc[df[\"label\"] == 0].apply(lambda x: longer_than_(x, number)))\n",
    "\n",
    "print(word_length)\n",
    "\n",
    "my_df = pd.DataFrame(word_length.items())\n",
    "ax = sns.barplot(x=0, y=1, data=my_df)\n",
    "ax.set(xlabel = 'Number of letters', ylabel='Number of words in ', title='Amount of words with nb letters for non fake news')"
   ]
  },
  {
   "source": [
    "Export to file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"../data/transformed/wrangled.csv\")"
   ]
  }
 ]
}